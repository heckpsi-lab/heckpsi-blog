---
title: 我们是否存在一个数据量越大，处理起来反而越快的程序？
date: 2014-10-19 12:14:47
tags: [算法,数学]
---

~~试图想这个问题的我一定是没有吃药。~~

首先，这个问题的存在是非常违背常识的。因为我们总会觉得数据量越大处理起来一定会越费劲，那么耗时一定会更长。但是讨论这个问题并不是毫无意义的。这个问题和 P=NP 问题一样，看起来非常的离谱，但是却也是细思极恐的问题。因为你很难想到使用哪个数学工具来证明这个问题的不可能性。而这个问题更离谱一点的问题在于，我们似乎能用数学方法证明一个数据量越大，处理起来反而越快的程序是存在的。

<!--more-->

要像证明这个问题我们应该从算法分析的基本工具 [大 O 符号](http://zh.wikipedia.org/wiki/%E5%A4%A7O%E7%AC%A6%E5%8F%B7) 出发。一个最简单的例子是是否存在一个 O(1/n) 的算法，使得当数据足够大时，运算的时间渐进于 1/n，如果存在这种情况，显然地，存在一个数据量越大，处理起来反而越快的程序。当我们用大 O 符号的定义进行证明的时候我们完全找不到任何有问题的地方，可以很容易地发现 O(1/n) 是满足大O符号的一切定义的。那么 O(1/n) 真的是存在的吗？

虽然数学上看起来存在一个满足的程序。那么谁能写出这样的程序呢？似乎现实生活中从未见过这样的程序。但是，今天在翻阅 StackOverFlow 的时候，我似乎见到了 [这样的程序](http://stackoverflow.com/questions/905551/are-there-any-o1-n-algorithms)。

```python
def get_faster(list):
  how_long = (1 / len(list)) * 100000
  sleep(how_long)
```

这个程序是这样的，简单来说，就是读取一串数据后，使机器暂停输入数据量的倒数时间。这个程序看起来是完全满足 O(1/n) 的，因为数据越多，运行越快。但，这个程序真的是 O(1/n) 吗？完全不是，这程序是一个 O(1)。因为当数据量足够大时，决定程序运行速度的将不再是机器暂停的时间，而是你计算数据量倒数的时间，而这个时间和输入的数据量无关，由于1，也就是 n^0 比 1/n，也就是 n^-1 高一阶，这个程序实际上是 O(1) 而不是 O(1/n) 的。

然后从这个程序出发我们再来考虑一下，O(1/n) 不存在的根本原因。其实根本原因出在图灵机或者冯诺依曼机上。当输入的数据量足够大的时候，O(1/n) 的运算时间会无限趋近于0。而实际上无论是图灵机还是冯诺依曼机，所有的硬件操作都存在一个最小的单位时间。这使得无论如何，程序的运行时间至少是一个最小的单位时间的，而这个时间迫使你算法的效率最小不可能小于 O(1)。

于是，我们知道了，在数学上也许是存在一个 O(1/n) 的，但是在图灵机、冯诺依曼机以及在此基础上发展的所有现代计算机都是不可能存在一个 O(1/n)。

那么回到我们开头的问题，存在一个数据量越大，处理起来反而越快的程序吗？事实上是存在的，上述例子程序就是一个这样的程序。但是当数据足够大时，运行时间不会无限下降，而是趋向于一个常数时间，无论这个时间有多小。

